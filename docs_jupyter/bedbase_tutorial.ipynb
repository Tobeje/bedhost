{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BEDBASE Demo**\n",
    "\n",
    "The following demo has the purpose of demonstrating how to process, generate statistics and plots of BED files genrated by the R package Genomic Distributions using the REST API for the bedstat and bedbuncher pipelines. \n",
    "\n",
    "The general workflow for uploading bed files and their \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior to start the tutorial (files download)\n",
    "We need create a directory where we'll store the bedbase pipelines and files to be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir bedbase_tutorial\n",
    "cd bedbase_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the BED files and PEPs we'll need for this demo, we can easily do this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-19 12:48:12--  http://big.databio.org/example_data/bedbase_demo/bedbase_demo_files_justBED/bedbase_BEDfiles.tar.gz\n",
      "Resolving big.databio.org (big.databio.org)... 128.143.245.181\n",
      "Connecting to big.databio.org (big.databio.org)|128.143.245.181|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 60245813 (57M) [application/octet-stream]\n",
      "Saving to: ‘bedbase_BEDfiles.tar.gz’\n",
      "\n",
      "bedbase_BEDfiles.ta 100%[===================>]  57.45M   701KB/s    in 79s     \n",
      "\n",
      "2020-03-19 12:49:31 (742 KB/s) - ‘bedbase_BEDfiles.tar.gz’ saved [60245813/60245813]\n",
      "\n",
      "--2020-03-19 12:49:31--  http://big.databio.org/example_data/bedbase_demo/bedbase_demo_files_justBED/bedbase_demo_PEPs.tar.gz\n",
      "Resolving big.databio.org (big.databio.org)... 128.143.245.181\n",
      "Connecting to big.databio.org (big.databio.org)|128.143.245.181|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1374 (1.3K) [application/octet-stream]\n",
      "Saving to: ‘bedbase_demo_PEPs.tar.gz’\n",
      "\n",
      "bedbase_demo_PEPs.t 100%[===================>]   1.34K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-19 12:49:31 (109 MB/s) - ‘bedbase_demo_PEPs.tar.gz’ saved [1374/1374]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget http://big.databio.org/example_data/bedbase_demo/bedbase_demo_files_justBED/bedbase_BEDfiles.tar.gz     \n",
    "wget http://big.databio.org/example_data/bedbase_demo/bedbase_demo_files_justBED/bedbase_demo_PEPs.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use our files and PEPs, we need to untar them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedbase_BEDfiles/\n",
      "bedbase_BEDfiles/GSE105977_ENCFF449EZT_optimal_idr_thresholded_peaks_hg19.bed.gz\n",
      "bedbase_BEDfiles/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE105587_ENCFF413ANK_peaks_hg19.bed.gz\n",
      "bedbase_BEDfiles/GSM2423312_ENCFF155HVK_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE105977_ENCFF617QGK_optimal_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE91663_ENCFF316ASR_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSM2423313_ENCFF722AOG_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE105587_ENCFF809OOE_conservative_idr_thresholded_peaks_hg19.bed.gz\n",
      "bedbase_BEDfiles/GSM2827349_ENCFF196DNQ_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE91663_ENCFF553KIK_optimal_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE91663_ENCFF319TPR_conservative_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE105977_ENCFF634NTU_peaks_hg19.bed.gz\n",
      "bedbase_BEDfiles/GSE105977_ENCFF937CGY_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSM2827350_ENCFF928JXU_peaks_GRCh38.bed.gz\n",
      "bedbase_BEDfiles/GSE105977_ENCFF793SZW_conservative_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bedbase_demo_PEPs/\n",
      "bedbase_demo_PEPs/bedstat_annotation_sheet.csv\n",
      "bedbase_demo_PEPs/bedbuncher_config.yaml\n",
      "bedbase_demo_PEPs/bedbase_configuration.yaml\n",
      "bedbase_demo_PEPs/bedbuncher_query.csv\n",
      "bedbase_demo_PEPs/bedstat_config.yaml\n"
     ]
    }
   ],
   "source": [
    "tar -zxvf bedbase_BEDfiles.tar.gz\n",
    "tar -zxvf bedbase_demo_PEPs.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First part of the tutorial (insert BED files stats into elastic)\n",
    "\n",
    "\n",
    "### 1) Create a PEP describing the BED files to process\n",
    "\n",
    "In order to get started, we'll need a PEP [Portable Encapsulated project](https://pepkit.github.io/). A PEP consists of 1) an annotation sheet (.csv) that contains information about the samples on a project and 2) a project config.yaml file that points to the sample annotation sheet. THe config file also has other components, such as derived attributes, that in this case point to the BED files to be processed. The following is an example of a config file using the derived attributes output_file_path and yaml_file to point to the `.bed.gz` files and their respective metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata:\n",
      "  sample_table: bedstat_annotation_sheet.csv\n",
      "  output_dir: ../bedstat/bedstat_pipeline_logs \n",
      "  pipeline_interfaces: ../bedstat/pipeline_interface.yaml\n",
      "\n",
      "constant_attributes: \n",
      "  output_file_path: \"source\"\n",
      "  yaml_file: \"source2\"\n",
      "  protocol: \"bedstat\"\n",
      "\n",
      "derived_attributes: [output_file_path, yaml_file]\n",
      "data_sources:\n",
      "  source: ../bedbase_BEDfiles/{file_name} \n",
      "  source2: ../bedstat/bedstat_pipeline_logs/submission/{sample_name}.yaml\n"
     ]
    }
   ],
   "source": [
    "cat bedbase_demo_PEPs/bedstat_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Download bedstat and the Bedbase configuration manager (bbconf)\n",
    "\n",
    "[bedstat](https://github.com/databio/bedstat) is a [pypiper](http://code.databio.org/pypiper/) pipeline that generates statistics and plots of BED files. [bbconf](https://github.com/databio/bbconf) implements convenience methods for interacting with the database backend, which in this case is defined by an Elastic search local cluster. For carrying out this demo, we'll be using the dev version of `bbconf` that can be download as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bedstat'...\n",
      "remote: Enumerating objects: 165, done.\u001b[K\n",
      "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
      "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
      "remote: Total 362 (delta 81), reused 106 (delta 43), pack-reused 197\u001b[K\n",
      "Receiving objects: 100% (362/362), 57.94 KiB | 1.26 MiB/s, done.\n",
      "Resolving deltas: 100% (155/155), done.\n",
      "Requirement already satisfied: piper in /home/jer4xy/.local/lib/python3.6/site-packages (0.12.1)\n",
      "Requirement already satisfied: ubiquerg>=0.4.5 in /home/jer4xy/.local/lib/python3.6/site-packages (from piper) (0.5.0)\n",
      "Requirement already satisfied: yacman in /home/jer4xy/.local/lib/python3.6/site-packages (from piper) (0.6.7)\n",
      "Requirement already satisfied: attmap>=0.12.5 in /home/jer4xy/.local/lib/python3.6/site-packages (from piper) (0.12.11)\n",
      "Requirement already satisfied: logmuse>=0.2.4 in /home/jer4xy/.local/lib/python3.6/site-packages (from piper) (0.2.6)\n",
      "Requirement already satisfied: psutil in /home/jer4xy/.local/lib/python3.6/site-packages (from piper) (5.7.0)\n",
      "Requirement already satisfied: pandas in /home/jer4xy/.local/lib/python3.6/site-packages (from piper) (1.0.2)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman->piper) (5.3)\n",
      "Requirement already satisfied: oyaml in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman->piper) (0.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->piper) (1.15.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->piper) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas->piper) (2018.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas->piper) (1.11.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: loopercli in /home/jer4xy/.local/lib/python3.6/site-packages (0.12.6)\n",
      "Requirement already satisfied: peppy>=0.22.2 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.22.3)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.4.3)\n",
      "Requirement already satisfied: pyyaml>=3.12 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (5.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from loopercli) (2.10)\n",
      "Requirement already satisfied: logmuse>=0.2.0 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.2.6)\n",
      "Requirement already satisfied: divvy>=0.3.1 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.4.0)\n",
      "Requirement already satisfied: attmap>=0.12.7 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.12.11)\n",
      "Requirement already satisfied: pandas>=0.20.2 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (1.0.2)\n",
      "Requirement already satisfied: ngstk>=0.0.1rc1 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.0.1rc2)\n",
      "Requirement already satisfied: ubiquerg>=0.4.5 in /home/jer4xy/.local/lib/python3.6/site-packages (from loopercli) (0.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->loopercli) (1.0)\n",
      "Requirement already satisfied: yacman>=0.5.0 in /home/jer4xy/.local/lib/python3.6/site-packages (from divvy>=0.3.1->loopercli) (0.6.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas>=0.20.2->loopercli) (2018.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->loopercli) (1.15.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->loopercli) (2.7.3)\n",
      "Requirement already satisfied: oyaml in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman>=0.5.0->divvy>=0.3.1->loopercli) (0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas>=0.20.2->loopercli) (1.11.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting git+https://github.com/databio/bbconf.git@dev\n",
      "  Cloning https://github.com/databio/bbconf.git (to revision dev) to /tmp/pip-req-build-k90lb9g3\n",
      "Requirement already satisfied (use --upgrade to upgrade): bbconf==0.0.2.dev0 from git+https://github.com/databio/bbconf.git@dev in /home/jer4xy/.local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: logmuse in /home/jer4xy/.local/lib/python3.6/site-packages (from bbconf==0.0.2.dev0) (0.2.6)\n",
      "Requirement already satisfied: elasticsearch in /home/jer4xy/.local/lib/python3.6/site-packages (from bbconf==0.0.2.dev0) (7.5.1)\n",
      "Requirement already satisfied: yacman>=0.6.6 in /home/jer4xy/.local/lib/python3.6/site-packages (from bbconf==0.0.2.dev0) (0.6.7)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3/dist-packages (from elasticsearch->bbconf==0.0.2.dev0) (1.22)\n",
      "Requirement already satisfied: ubiquerg>=0.4.9 in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman>=0.6.6->bbconf==0.0.2.dev0) (0.5.0)\n",
      "Requirement already satisfied: attmap>=0.12.9 in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman>=0.6.6->bbconf==0.0.2.dev0) (0.12.11)\n",
      "Requirement already satisfied: oyaml in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman>=0.6.6->bbconf==0.0.2.dev0) (0.9)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman>=0.6.6->bbconf==0.0.2.dev0) (5.3)\n",
      "Building wheels for collected packages: bbconf\n",
      "  Running setup.py bdist_wheel for bbconf ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-t0r6jqgo/wheels/86/ec/ae/8d3556156f53eca4b9c93e66c52a7f789ff9deb2b5a9c0663e\n",
      "Successfully built bbconf\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "git clone git@github.com:databio/bedstat\n",
    "# Install Python dependencies\n",
    "pip install piper --user\n",
    "pip install --user loopercli\n",
    "pip install git+https://github.com/databio/bbconf.git@dev --user\n",
    "# Install R dependencies\n",
    "#Rscript scripts/installRdeps.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to create a directory where we can store the stats and plots generated by `bedstat`. Additionally, we'll create a directory where we can store log and metadata files that we'll need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir bedstat/bedstat_output\n",
    "mkdir bedstat/bedstat_pipeline_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use bbconf, we'll need to create a minimal configuration.yaml file. The path to this configuration file can be stored in the environment variable `$BEDBASE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:\n",
      "  pipelines_output: ../bedstat/bedstat_output\n",
      "\n",
      "database:\n",
      "  host: localhost\n",
      "  bed_index: bed_index\n",
      "  bedset_index: bedset_index\n",
      "\n",
      "server:\n",
      "  host: 0.0.0.0\n",
      "  port: 8000\n"
     ]
    }
   ],
   "source": [
    "cat bedbase_demo_PEPs/bedbase_configuration.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Inititiate a local elasticsearch cluster\n",
    "\n",
    "In addition to generate statistics and plots, [bedstat](https://github.com/databio/bedstat) inserts JSON formatted metadata into an [elasticsearch](https://www.elastic.co/elasticsearch/?ultron=[EL]-[B]-[AMER]-US+CA-Exact&blade=adwords-s&Device=c&thor=elasticsearch&gclid=Cj0KCQjwjcfzBRCHARIsAO-1_Oq5mSdze16kripxT5_I__EeH9F-xUCz_khEvzGL7q_mqP62CahJ9SIaAg2BEALw_wcB) database that it'll later be used to search and extract files and information about them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If docker is not already installed, you can do so with the following commands\n",
    "#(make sure you have sudo permissions)\n",
    "\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-engine -y\n",
    "\n",
    "# Create a persistent volume to house elastic search data\n",
    "docker volume create es-data\n",
    "\n",
    "# Run the docker container for elasticsearch\n",
    "docker run -p 9200:9200 -p 9300:9300 -v es-data:/usr/share/elasticsearch/data -e \"xpack.ml.enabled=false\" \\\n",
    "  -e \"discovery.type=single-node\" elasticsearch:7.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Run the bedstat pipeline on the demo PEP\n",
    "To run [bedstat](https://github.com/databio/bedstat) and the other required pipelines in this demo, we will rely on the pipeline submission engine [looper](http://looper.databio.org/en/latest/). For detailed instructions in how to link a project to a pipeline, click [here](http://looper.databio.org/en/latest/linking-a-pipeline/). If the pipeline is being run from an HPC environment where docker is not available, we recommend running the pipeline using the `--no-db-commit` flag (this will only calculate statistics and generate plots but will not insert this information into the local elasticsearch cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: run (Looper version: 0.12.6)\n",
      "Reading sample annotations sheet: '/home/jer4xy/Desktop/bedbase_tutorial/bedbase_demo_PEPs/bedstat_annotation_sheet.csv'\n",
      "Storing sample table from file '/home/jer4xy/Desktop/bedbase_tutorial/bedbase_demo_PEPs/bedstat_annotation_sheet.csv'\n",
      "Activating compute package 'local'\n",
      "Finding pipelines for protocol(s): bedstat\n",
      "Known protocols: bedstat\n",
      "'/home/jer4xy/Desktop/bedbase_tutorial/bedbase_demo_PEPs/../bedstat/pipeline/bedstat.py' appears to attempt to run on import; does it lack a conditional on '__main__'? Using base type: Sample\n",
      "\u001b[36m## [1 of 15] bedbase_demo_db1 (bedstat)\u001b[0m\n",
      "Submission settings lack memory specification\n",
      "Writing script to /home/jer4xy/Desktop/bedstat/bedstat_pipeline_logs/submission/bedstat_bedbase_demo_db1.sub\n",
      "Job script (n=1; 0.00 Gb): ../bedstat/bedstat_pipeline_logs/submission/bedstat_bedbase_demo_db1.sub\n",
      "Compute node: cphg-5L9SYF2\n",
      "Start time: 2020-03-19 14:07:14\n",
      "### Pipeline run code and environment:\n",
      "\n",
      "*              Command:  `/home/jer4xy/Desktop/bedbase_tutorial/bedbase_demo_PEPs/../bedstat/pipeline/bedstat.py --bedfile /home/jer4xy/Desktop/bedbase_tutorial/bedbase_BEDfiles/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.bed.gz --genome hg38 --sample-yaml ../bedstat/bedstat_pipeline_logs/submission/bedbase_demo_db1.yaml -O ../bedstat/bedstat_pipeline_logs/results_pipeline --bedbase-config bedbase_demo_PEPs/bedbase_configuration.yaml --no-db-commit -R`\n",
      "*         Compute host:  cphg-5L9SYF2\n",
      "*          Working dir:  /home/jer4xy/Desktop/bedbase_tutorial\n",
      "*            Outfolder:  /home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/\n",
      "*  Pipeline started at:   (03-19 14:07:15) elapsed: 0.0 _TIME_\n",
      "\n",
      "### Version log:\n",
      "\n",
      "*       Python version:  3.6.7\n",
      "*          Pypiper dir:  `/home/jer4xy/.local/lib/python3.6/site-packages/pypiper`\n",
      "*      Pypiper version:  0.12.1\n",
      "*         Pipeline dir:  `/home/jer4xy/Desktop/bedbase_tutorial/bedstat/pipeline`\n",
      "*     Pipeline version:  None\n",
      "*        Pipeline hash:  bd90e7cbb5a8146fe95bce6c38548da519cb7602\n",
      "*      Pipeline branch:  * master\n",
      "*        Pipeline date:  2020-03-18 10:30:43 -0400\n",
      "\n",
      "### Arguments passed to pipeline:\n",
      "\n",
      "*     `bedbase_config`:  `bedbase_demo_PEPs/bedbase_configuration.yaml`\n",
      "*            `bedfile`:  `/home/jer4xy/Desktop/bedbase_tutorial/bedbase_BEDfiles/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.bed.gz`\n",
      "*        `config_file`:  `bedstat.yaml`\n",
      "*              `cores`:  `1`\n",
      "*              `dirty`:  `False`\n",
      "*       `force_follow`:  `False`\n",
      "*    `genome_assembly`:  `hg38`\n",
      "*              `input`:  `None`\n",
      "*             `input2`:  `None`\n",
      "*     `just_db_commit`:  `False`\n",
      "*             `logdev`:  `False`\n",
      "*                `mem`:  `4000`\n",
      "*          `new_start`:  `False`\n",
      "*       `no_db_commit`:  `True`\n",
      "*      `output_parent`:  `../bedstat/bedstat_pipeline_logs/results_pipeline`\n",
      "*            `recover`:  `True`\n",
      "*        `sample_name`:  `None`\n",
      "*        `sample_yaml`:  `../bedstat/bedstat_pipeline_logs/submission/bedbase_demo_db1.yaml`\n",
      "*             `silent`:  `False`\n",
      "*   `single_or_paired`:  `single`\n",
      "*           `testmode`:  `False`\n",
      "*          `verbosity`:  `None`\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Found lock file: /home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/lock.GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.json\n",
      "Overwriting target...\n",
      "Target to produce: `/home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.json`  \n",
      "\n",
      "> `Rscript /home/jer4xy/Desktop/bedbase_tutorial/bedstat/tools/regionstat.R --bedfile=/home/jer4xy/Desktop/bedbase_tutorial/bedbase_BEDfiles/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.bed.gz --fileId=GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38 --outputfolder=/home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984 --genome=hg38 --digest=78c0e4753d04b238fc07e4ebe5a02984` (29777)\n",
      "<pre>\n",
      "Loading required package: GenomicRanges\n",
      "Loading required package: stats4\n",
      "Loading required package: BiocGenerics\n",
      "Loading required package: parallel\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colMeans,\n",
      "    colnames, colSums, dirname, do.call, duplicated, eval, evalq,\n",
      "    Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply,\n",
      "    lengths, Map, mapply, match, mget, order, paste, pmax, pmax.int,\n",
      "    pmin, pmin.int, Position, rank, rbind, Reduce, rowMeans, rownames,\n",
      "    rowSums, sapply, setdiff, sort, table, tapply, union, unique,\n",
      "    unsplit, which, which.max, which.min\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "Loading required package: IRanges\n",
      "Loading required package: GenomeInfoDb\n",
      "[1] \"Plotting: /home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38_tssdist\"\n",
      "BSAggregate: Calculating sizes. You can speed this up by supplying a regionsGRL.length vector...Done counting regionsGRL lengths.\n",
      "Finding overlaps...\n",
      "Setting regionIDs...\n",
      "jExpr: .N\n",
      "Combining...\n",
      "[1] \"Plotting: /home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38_chrombins\"\n",
      "Loading required namespace: BSgenome.Hsapiens.UCSC.hg38.masked\n",
      "[1] \"Plotting: /home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38_gccontent\"\n",
      "promoterCore :\tfound 11017\n",
      "promoterProx :\tfound 2911\n",
      "exon :\tfound 11031\n",
      "intron :\tfound 22553\n",
      "[1] \"Plotting: /home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38_partitions\"\n",
      "Warning messages:\n",
      "1: In .Seqinfo.mergexy(x, y) :\n",
      "  Each of the 2 combined objects has sequence levels not in the other:\n",
      "  - in 'x': chrUn_GL000224v1, chr17_GL000205v2_random, chrUn_GL000219v1, chrUn_GL000195v1, chrUn_GL000218v1, chr22_KI270733v1_random, chr1_KI270706v1_random, chrUn_GL000220v1, chrUn_GL000216v2, chr17_KI270729v1_random, chr1_KI270713v1_random\n",
      "  - in 'y': chrCHR_HG107_PATCH, chrCHR_HG126_PATCH, chrCHR_HG1311_PATCH, chrCHR_HG1342_HG2282_PATCH, chrCHR_HG1362_PATCH, chrCHR_HG142_HG150_NOVEL_TEST, chrCHR_HG151_NOVEL_TEST, chrCHR_HG1832_PATCH, chrCHR_HG2021_PATCH, chrCHR_HG2023_PATCH, chrCHR_HG2030_PATCH, chrCHR_HG2058_PATCH, chrCHR_HG2063_PATCH, chrCHR_HG2066_PATCH, chrCHR_HG2072_PATCH, chrCHR_HG2095_PATCH, chrCHR_HG2104_PATCH, chrCHR_HG2116_PATCH, chrCHR_HG2191_PATCH, chrCHR_HG2213_PATCH, chrCHR_HG2217_PATCH, chrCHR_HG2232_PATCH, chrCHR_HG2233_PATCH, chrCHR_HG2235_PATCH, chrCHR_HG2239_PATCH, chrCHR_HG2247_PATCH, chrCHR_HG2288_HG2289_PATCH, chrCHR_HG2290_PATCH, chrCHR_HG2291_PATCH, chrCHR_HG2334_PATCH, chrCHR_HG26_PATCH, ch [... truncated]\n",
      "2: In .Seqinfo.mergexy(x, y) :\n",
      "  Each of the 2 combined objects has sequence levels not in the other:\n",
      "  - in 'x': chrUn_GL000224v1, chr17_GL000205v2_random, chrUn_GL000219v1, chrUn_GL000195v1, chrUn_GL000218v1, chr22_KI270733v1_random, chr1_KI270706v1_random, chrUn_GL000220v1, chrUn_GL000216v2, chr17_KI270729v1_random, chr1_KI270713v1_random\n",
      "  - in 'y': chrCHR_HG107_PATCH, chrCHR_HG126_PATCH, chrCHR_HG1311_PATCH, chrCHR_HG1342_HG2282_PATCH, chrCHR_HG1362_PATCH, chrCHR_HG142_HG150_NOVEL_TEST, chrCHR_HG151_NOVEL_TEST, chrCHR_HG1832_PATCH, chrCHR_HG2021_PATCH, chrCHR_HG2023_PATCH, chrCHR_HG2030_PATCH, chrCHR_HG2058_PATCH, chrCHR_HG2063_PATCH, chrCHR_HG2066_PATCH, chrCHR_HG2072_PATCH, chrCHR_HG2095_PATCH, chrCHR_HG2104_PATCH, chrCHR_HG2116_PATCH, chrCHR_HG2191_PATCH, chrCHR_HG2213_PATCH, chrCHR_HG2217_PATCH, chrCHR_HG2232_PATCH, chrCHR_HG2233_PATCH, chrCHR_HG2235_PATCH, chrCHR_HG2239_PATCH, chrCHR_HG2247_PATCH, chrCHR_HG2288_HG2289_PATCH, chrCHR_HG2290_PATCH, chrCHR_HG2291_PATCH, chrCHR_HG2334_PATCH, chrCHR_HG26_PATCH, ch [... truncated]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: In .Seqinfo.mergexy(x, y) :\n",
      "  Each of the 2 combined objects has sequence levels not in the other:\n",
      "  - in 'x': chrUn_GL000224v1, chr17_GL000205v2_random, chrUn_GL000219v1, chrUn_GL000195v1, chrUn_GL000218v1, chr22_KI270733v1_random, chr1_KI270706v1_random, chrUn_GL000220v1, chrUn_GL000216v2, chr17_KI270729v1_random, chr1_KI270713v1_random\n",
      "  - in 'y': chrCHR_HG107_PATCH, chrCHR_HG126_PATCH, chrCHR_HG1311_PATCH, chrCHR_HG1342_HG2282_PATCH, chrCHR_HG1362_PATCH, chrCHR_HG142_HG150_NOVEL_TEST, chrCHR_HG151_NOVEL_TEST, chrCHR_HG1832_PATCH, chrCHR_HG2021_PATCH, chrCHR_HG2023_PATCH, chrCHR_HG2030_PATCH, chrCHR_HG2058_PATCH, chrCHR_HG2063_PATCH, chrCHR_HG2066_PATCH, chrCHR_HG2072_PATCH, chrCHR_HG2095_PATCH, chrCHR_HG2104_PATCH, chrCHR_HG2116_PATCH, chrCHR_HG2191_PATCH, chrCHR_HG2213_PATCH, chrCHR_HG2217_PATCH, chrCHR_HG2232_PATCH, chrCHR_HG2233_PATCH, chrCHR_HG2235_PATCH, chrCHR_HG2239_PATCH, chrCHR_HG2247_PATCH, chrCHR_HG2288_HG2289_PATCH, chrCHR_HG2290_PATCH, chrCHR_HG2291_PATCH, chrCHR_HG2334_PATCH, chrCHR_HG26_PATCH, ch [... truncated]\n",
      "4: In .Seqinfo.mergexy(x, y) :\n",
      "  Each of the 2 combined objects has sequence levels not in the other:\n",
      "  - in 'x': chrUn_GL000224v1, chr17_GL000205v2_random, chrUn_GL000219v1, chrUn_GL000195v1, chrUn_GL000218v1, chr22_KI270733v1_random, chr1_KI270706v1_random, chrUn_GL000220v1, chrUn_GL000216v2, chr17_KI270729v1_random, chr1_KI270713v1_random\n",
      "  - in 'y': chrCHR_HG107_PATCH, chrCHR_HG126_PATCH, chrCHR_HG1311_PATCH, chrCHR_HG1342_HG2282_PATCH, chrCHR_HG1362_PATCH, chrCHR_HG142_HG150_NOVEL_TEST, chrCHR_HG151_NOVEL_TEST, chrCHR_HG1832_PATCH, chrCHR_HG2021_PATCH, chrCHR_HG2023_PATCH, chrCHR_HG2030_PATCH, chrCHR_HG2058_PATCH, chrCHR_HG2063_PATCH, chrCHR_HG2066_PATCH, chrCHR_HG2072_PATCH, chrCHR_HG2095_PATCH, chrCHR_HG2104_PATCH, chrCHR_HG2116_PATCH, chrCHR_HG2191_PATCH, chrCHR_HG2213_PATCH, chrCHR_HG2217_PATCH, chrCHR_HG2232_PATCH, chrCHR_HG2233_PATCH, chrCHR_HG2235_PATCH, chrCHR_HG2239_PATCH, chrCHR_HG2247_PATCH, chrCHR_HG2288_HG2289_PATCH, chrCHR_HG2290_PATCH, chrCHR_HG2291_PATCH, chrCHR_HG2334_PATCH, chrCHR_HG26_PATCH, ch [... truncated]\n",
      "Warning message:\n",
      "system call failed: Cannot allocate memory \n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:28. Running peak memory: 0.397GB.  \n",
      "  PID: 29777;\tCommand: Rscript;\tReturn code: 0;\tMemory used: 0.397GB\n",
      "\n",
      "\n",
      "### Pipeline completed. Epilogue\n",
      "*        Elapsed time (this run):  0:00:28\n",
      "*  Total elapsed time (all runs):  0:00:28\n",
      "*         Peak memory (this run):  0.3972 GB\n",
      "*        Pipeline completed time: 2020-03-19 14:07:43\n",
      "Removed existing flag: '/home/jer4xy/Desktop/bedstat/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/bedstat-pipeline_failed.flag'\n",
      "\n",
      "Looper finished\n",
      "Samples valid for job generation: 1 of 1\n",
      "Successful samples: 1 of 1\n",
      "Commands submitted: 1 of 1\n",
      "Jobs submitted: 1\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#looper run bedbase_demo_PEPs/bedstat_config.yaml --no-db-commit --compute local --limit 1 -R\n",
    "\n",
    "looper run bedbase_demo_PEPs/bedstat_config.yaml --bedbase-config bedbase_demo_PEPs/bedbase_configuration.yaml \\\n",
    "--no-db-commit --compute local --limit 1 -R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have generated plots and statistics, we can insert them into our local elastic search cluster running the bedstat pipeline with the `--just-db-commit` flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looper run bedbase_demo_PEPs/bedstat_config.yaml  --just-db-commit --compute local -R\n",
    "\n",
    "looper run bedbase_demo_PEPs/bedstat_config.yaml --bedbase-config bedbase_demo_PEPs/bedbase_configuration.yaml \\\n",
    "--just-db-commit --compute local -R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous steps have been executed, our BED files should be available for query on our local elastic search cluster. Files can be queried using the `bedbuncher` pipeline described in the below section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second part of the tutorial (use bedbuncher to create bedsets)\n",
    "\n",
    "### 1) Create a new PEP describing the bedset name and specific JSON query  \n",
    "[bedbuncher](https://github.com/databio/bedbuncher) is a pipeline designed to create bedsets (sets of BED files retrieved from bedbase). In order to create bedsets, we will need to create an additional PEP describing the query as well as attributes such as the name assigned to the newly created bedset. This configuration file should descibe the path to the `JSON` query file. THe configuration file should have the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_name,bedset_name,JSONquery_name,bbconfig_name,JSONquery_path,output_folder_path\n",
      "bedset1,bedbase_demo_bedset,test_query,bedbase_configuration,source1,source2\n"
     ]
    }
   ],
   "source": [
    "cat bedbase_demo_PEPs/bedbuncher_query.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata:\n",
      "  sample_table: bedbuncher_query.csv\n",
      "  output_dir: ../bedbuncher/bedbuncher_pipeline_logs\n",
      "  pipeline_interfaces: ../bedbuncher/pipeline_interface.yaml \n",
      "\n",
      "derived_attributes: [JSONquery_path, bbconfig_path]\n",
      "data_sources:\n",
      "  source1: ../bedbuncher/tests/{JSONquery_name}.json\n",
      "  source2: ./{bbconfig_name}.yaml\n",
      "constant_attributes:\n",
      "  protocol: \"bedbuncher\"\n"
     ]
    }
   ],
   "source": [
    "cat bedbase_demo_PEPs/bedbuncher_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Download the bedbuncher pipeline \n",
    "\n",
    "To download `bedbuncher`, simply clone the repository from github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bedbuncher'...\n",
      "Warning: Permanently added the RSA host key for IP address '140.82.114.3' to the list of known hosts.\n",
      "remote: Enumerating objects: 39, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 235 (delta 22), reused 26 (delta 12), pack-reused 196\u001b[K\n",
      "Receiving objects: 100% (235/235), 54.59 KiB | 1.24 MiB/s, done.\n",
      "Resolving deltas: 100% (130/130), done.\n"
     ]
    }
   ],
   "source": [
    "git clone git@github.com:databio/bedbuncher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the feats of `bedbuncher` is [iGD](https://github.com/databio/iGD) database creation from the files in the bedset. [iGD](https://github.com/databio/iGD) can be installed as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/databio/iGD.git\n",
    "cd iGD\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Run the bedbuncher pipeline using Looper \n",
    "\n",
    "Once we have cloned the `bedbuncher` repository, we just need to point to the config file previously shown and pass the location of the `bedbase` configuration file to the argument `--bedbase-config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ..\n",
    "looper run project/cfg.yaml --bedbase-config bedbase_demo_PEPs/bedbase_configuration.yaml  --compute local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third part of the demo (run local instance of bedhost)\n",
    "\n",
    "The last part of the tutorial consists on running a local instance of [bedhost](https://github.com/databio/bedhost/tree/master) (a REST API for bedstat and bedbuncher produced outputs) in order to explore and download output files. To access the API, we'll need to download the dev branch of the github repository as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bedhost'...\n",
      "remote: Enumerating objects: 107, done.\u001b[K\n",
      "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
      "remote: Total 618 (delta 69), reused 65 (delta 29), pack-reused 511\u001b[K\n",
      "Receiving objects: 100% (618/618), 171.60 KiB | 423.00 KiB/s, done.\n",
      "Resolving deltas: 100% (402/402), done.\n",
      "Processing ./bedhost\n",
      "Requirement already satisfied: pyyaml in /home/jer4xy/.local/lib/python3.6/site-packages (from bedhost==0.0.1) (5.3)\n",
      "Collecting aiofiles (from bedhost==0.0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/f2/a67a23bc0bb61d88f82aa7fb84a2fb5f278becfbdc038c5cbb36c31feaf1/aiofiles-0.4.0-py3-none-any.whl\n",
      "Collecting fastapi (from bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/5b/46c084c174fc69b2a7e1d9c22d014f39fb677d9a7635f24734ef56e0fb53/fastapi-0.52.0-py3-none-any.whl (47kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from bedhost==0.0.1) (2.10)\n",
      "Collecting starlette (from bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/2e/f56602beda25b376bbaaeadb626cf212b673457075ffed0dd12969ad6014/starlette-0.13.2-py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.8MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting uvicorn>=0.7.1 (from bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/2a/b7fa32c8b89746308cc4acb333a320bbe2263d522665b3ef21a6fcdcd898/uvicorn-0.11.3-py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.4MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting elasticsearch-dsl<8.0.0,>=7.0.0 (from bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/46/b03326c44aa9693b7879d17fce42fa412470e43cf6035e8addfc5af634c6/elasticsearch_dsl-7.1.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting python-multipart (from bedhost==0.0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/46/40/a933ac570bf7aad12a298fc53458115cc74053474a72fbb8201d7dc06d3d/python-multipart-0.0.5.tar.gz\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from bedhost==0.0.1) (2.18.4)\n",
      "Requirement already satisfied: yacman in /home/jer4xy/.local/lib/python3.6/site-packages (from bedhost==0.0.1) (0.6.7)\n",
      "Requirement already satisfied: bbconf>=0.0.2-dev in /home/jer4xy/.local/lib/python3.6/site-packages (from bedhost==0.0.1) (0.0.2.dev0)\n",
      "Collecting pydantic<2.0.0,>=0.32.2 (from fastapi->bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/29/7cbee55671fb414c9d9352af83d1f4e579e01324be6bbdb59985bf3a2401/pydantic-1.4-cp36-cp36m-manylinux1_x86_64.whl (7.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.5MB 867kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->bedhost==0.0.1) (1.0)\n",
      "Collecting websockets==8.* (from uvicorn>=0.7.1->bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/cb/c35513c4a0ff24ca13e33f7336ba8c1a864449fad9fea8e37abdad11c38d/websockets-8.1-cp36-cp36m-manylinux1_x86_64.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 2.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting click==7.* (from uvicorn>=0.7.1->bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/c0/4d8f43a9b16e289f36478422031b8a63b54b6ac3b1ba605d602f10dd54d6/click-7.1.1-py2.py3-none-any.whl (82kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 2.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting h11<0.10,>=0.8 (from uvicorn>=0.7.1->bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\" (from uvicorn>=0.7.1->bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/2e/462e7a25b787d2b40cf6c9864a9e702f358349fc9cfb77e83c38acb73048/uvloop-0.14.0.tar.gz (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 614kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\" (from uvicorn>=0.7.1->bedhost==0.0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/dc1e7e8f4049ab70d52c9690ec10652e268ab2542853033cc1d539594102/httptools-0.1.1-cp36-cp36m-manylinux1_x86_64.whl (216kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 692kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from elasticsearch-dsl<8.0.0,>=7.0.0->bedhost==0.0.1) (2.7.3)\n",
      "Requirement already satisfied: elasticsearch<8.0.0,>=7.0.0 in /home/jer4xy/.local/lib/python3.6/site-packages (from elasticsearch-dsl<8.0.0,>=7.0.0->bedhost==0.0.1) (7.5.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from elasticsearch-dsl<8.0.0,>=7.0.0->bedhost==0.0.1) (1.11.0)\n",
      "Requirement already satisfied: oyaml in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman->bedhost==0.0.1) (0.9)\n",
      "Requirement already satisfied: ubiquerg>=0.4.9 in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman->bedhost==0.0.1) (0.5.0)\n",
      "Requirement already satisfied: attmap>=0.12.9 in /home/jer4xy/.local/lib/python3.6/site-packages (from yacman->bedhost==0.0.1) (0.12.11)\n",
      "Requirement already satisfied: logmuse in /home/jer4xy/.local/lib/python3.6/site-packages (from bbconf>=0.0.2-dev->bedhost==0.0.1) (0.2.6)\n",
      "Collecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic<2.0.0,>=0.32.2->fastapi->bedhost==0.0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3/dist-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch-dsl<8.0.0,>=7.0.0->bedhost==0.0.1) (1.22)\n",
      "Building wheels for collected packages: bedhost, python-multipart, uvloop\n",
      "  Running setup.py bdist_wheel for bedhost ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-kejkj2dm/wheels/4e/af/33/5de28ee4fe48dea37c642e42ece111a557cb116dbe11abe2c2\n",
      "  Running setup.py bdist_wheel for python-multipart ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jer4xy/.cache/pip/wheels/f0/e6/66/14a866a3cbd6a0cabfbef91f7edf40aa03595ef6c88d6d1be4\n",
      "  Running setup.py bdist_wheel for uvloop ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jer4xy/.cache/pip/wheels/a8/72/90/587632ba94698c7df7a1327f8149026a47bef6acb7b45cda16\n",
      "Successfully built bedhost python-multipart uvloop\n",
      "Installing collected packages: aiofiles, dataclasses, pydantic, starlette, fastapi, websockets, click, h11, uvloop, httptools, uvicorn, elasticsearch-dsl, python-multipart, bedhost\n",
      "Successfully installed aiofiles-0.4.0 bedhost-0.0.1 click-7.1.1 dataclasses-0.7 elasticsearch-dsl-7.1.0 fastapi-0.52.0 h11-0.9.0 httptools-0.1.1 pydantic-1.4 python-multipart-0.0.5 starlette-0.13.2 uvicorn-0.11.3 uvloop-0.14.0 websockets-8.1\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "git clone git@github.com:databio/bedhost\n",
    "pip install bedhost/. --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to run the following command, making sure to point to the previously described bedbase config.yaml file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting itsdangerous\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: itsdangerous\n",
      "Successfully installed itsdangerous-1.1.0\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "DEBU 2020-03-19 14:37:24,007 | bedhost:est:266 > Configured logger 'bedhost' using logmuse v0.2.6 \n",
      "DEBU 14:37:24 | bbconf:est:266 > Configured logger 'bbconf' using logmuse v0.2.6 \n",
      "INFO 14:37:24 | bbconf:bbconf:61 > Established connection with Elasticsearch: localhost \n",
      "DEBU 14:37:24 | bbconf:bbconf:63 > Elasticsearch info:\n",
      "{'name': '3c0f2923e411', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'nZZ-pE_5T-SB1lCM0E8dDg', 'version': {'number': '7.5.1', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '3ae9ac9a93c95bd0cdc054951cf95d88e1e18d96', 'build_date': '2019-12-16T22:57:37.835892Z', 'build_snapshot': False, 'lucene_version': '8.3.0', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'} \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jer4xy/.local/bin/bedhost\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/jer4xy/.local/lib/python3.6/site-packages/bedhost/main.py\", line 253, in main\n",
      "    StaticFiles(directory=bbc[CFG_PATH_KEY][CFG_PIP_OUTPUT_KEY]), name=BED_INDEX)\n",
      "  File \"/home/jer4xy/.local/lib/python3.6/site-packages/starlette/applications.py\", line 110, in mount\n",
      "    self.router.mount(path, app=app, name=name)\n",
      "  File \"/home/jer4xy/.local/lib/python3.6/site-packages/starlette/routing.py\", line 587, in mount\n",
      "    route = Mount(path, app=app, name=name)\n",
      "  File \"/home/jer4xy/.local/lib/python3.6/site-packages/starlette/routing.py\", line 301, in __init__\n",
      "    assert path == \"\" or path.startswith(\"/\"), \"Routed paths must start with '/'\"\n",
      "AssertionError: Routed paths must start with '/'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "pip install itsdangerous --user\n",
    "bedhost serve -c  bedbase_demo_PEPs/bedbase_configuration.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have stored the path to the bedbase config in the environment variable `$BEDBASE` (suggested), it's not neccesary to specify the path to the config file to start bedhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedhost serve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
