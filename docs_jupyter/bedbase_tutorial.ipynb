{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEDBASE workflow tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following demo has the purpose of demonstrating how to process, generate statistics and plots of BED files generated by the R package Genomic Distributions using the `bedhost` REST API for the bedstat and bedbuncher pipelines output. \n",
    "\n",
    "Notes:\n",
    "\n",
    "- If this hasn't been already done, we recommend starting this jupyter notebook enabling sudo permissions since steps such as downloading `docker` or running an elasticsearch `docker` container won't be executed otherwise. This can be done with `sudo jupyter notebook --allow-root`\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Create-a-tutorial-directory-and-download-required-files-and-pipelines\" data-toc-modified-id=\"Create-a-tutorial-directory-and-download-required-files-and-pipelines-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Create a tutorial directory and download required files and pipelines</a></span></li><li><span><a href=\"#BEDSTAT:-Generate-statistics-and-plots-of-BED-files\" data-toc-modified-id=\"BEDSTAT:-Generate-statistics-and-plots-of-BED-files-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>BEDSTAT: Generate statistics and plots of BED files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-PEP-describing-the-BED-files-to-process\" data-toc-modified-id=\"Create-a-PEP-describing-the-BED-files-to-process-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Create a PEP describing the BED files to process</a></span></li><li><span><a href=\"#Download-the-bedbase-configuration-manager-(bbconf)-and-install-bedstat-dependencies\" data-toc-modified-id=\"Download-the-bedbase-configuration-manager-(bbconf)-and-install-bedstat-dependencies-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Download the bedbase configuration manager (bbconf) and install bedstat dependencies</a></span></li><li><span><a href=\"#Inititiate-a-local-elasticsearch-cluster\" data-toc-modified-id=\"Inititiate-a-local-elasticsearch-cluster-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inititiate a local elasticsearch cluster</a></span></li><li><span><a href=\"#Run-bedstat--on-the-demo-PEP\" data-toc-modified-id=\"Run-bedstat--on-the-demo-PEP-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Run bedstat  on the demo PEP</a></span></li></ul></li><li><span><a href=\"#BEDBUNCHER:-Create-bedsets-and-their-respective-statistics\" data-toc-modified-id=\"BEDBUNCHER:-Create-bedsets-and-their-respective-statistics-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>BEDBUNCHER: Create bedsets and their respective statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-new-PEP-describing-the-bedset-name-and-specific-JSON-query\" data-toc-modified-id=\"Create-a-new-PEP-describing-the-bedset-name-and-specific-JSON-query-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create a new PEP describing the bedset name and specific JSON query</a></span></li><li><span><a href=\"#Create-outputs-directory-and-install-bedbuncher-CML-dependencies\" data-toc-modified-id=\"Create-outputs-directory-and-install-bedbuncher-CML-dependencies-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create outputs directory and install bedbuncher CML dependencies</a></span></li><li><span><a href=\"#Run-bedbuncher-using-Looper\" data-toc-modified-id=\"Run-bedbuncher-using-Looper-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Run bedbuncher using Looper</a></span></li></ul></li><li><span><a href=\"#BEDHOST:--API-to-explore-pipeline-outputs\" data-toc-modified-id=\"BEDHOST:--API-to-explore-pipeline-outputs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BEDHOST:  API to explore pipeline outputs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tutorial directory and download required files and pipelines \n",
    "We need create a directory where we'll store the bedbase pipelines and files to be processed. We'll also need to create an environment variable that points to the tutorial directory (we'll need this variable in section 3 of the tutorial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $HOME/Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir bedbase_tutorial\n",
    "cd bedbase_tutorial\n",
    "export BBTUTORIAL=`pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the files we'll need for this tutorial, we can easily do it with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget http://big.databio.org/example_data/bedbase_tutorial/bed_files.tar.gz     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded files are compressed so we'll need to untar them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar -zxvf bed_files.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we'll download the 3 core pipelines and tools needed to complete this tutorial: `bedstat`, `bedbuncher` and `bedhost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone git@github.com:databio/bedstat\n",
    "git clone git@github.com:databio/bedbuncher\n",
    "git clone git@github.com:databio/bedhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEDSTAT: Generate statistics and plots of BED files \n",
    "\n",
    "\n",
    "### Create a PEP describing the BED files to process\n",
    "\n",
    "In order to get started, we'll need a PEP [Portable Encapsulated project](https://pepkit.github.io/). A PEP consists of 1) an annotation sheet (.csv) that contains information about the samples on a project and 2) a project config.yaml file that points to the sample annotation sheet. The config file also has other components, such as derived attributes, that in this case point to the BED files to be processed. The following is an example of a config file using the derived attributes `output_file_path` and `yaml_file` to point to the `.bed.gz` files and their respective metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat bedhost/tutorial_files/PEPs/bedstat_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the bedbase configuration manager (bbconf) and install bedstat dependencies\n",
    "\n",
    "[bedstat](https://github.com/databio/bedstat) is a [pypiper](http://code.databio.org/pypiper/) pipeline that generates statistics and plots of BED files. Additionally, [bedstat](https://github.com/databio/bedstat) relies in\n",
    "[bbconf](https://github.com/databio/bbconf), the `bedbase` configuration manager which implements convenience methods for interacting with an elasticsearch database, where our files metadata will be placed. For carrying out this demo, we'll be using the dev version of `bbconf` that can be downloaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the bedbase configuration manager\n",
    "pip install git+https://github.com/databio/bbconf.git@dev --user > bbconf_log.txt\n",
    "\n",
    "# Install Python dependencies\n",
    "pip install piper --user > piper_log.txt\n",
    "\n",
    "# Install R dependencies\n",
    "Rscript bedstat/scripts/installRdeps.R > R_deps.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to create a directory where we can store the stats and plots generated by `bedstat`. Additionally, we'll create a directory where we can store log and metadata files that we'll need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir outputs\n",
    "mkdir outputs/bedstat_output\n",
    "mkdir outputs/bedstat_output/bedstat_pipeline_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use bbconf, we'll need to create a minimal configuration.yaml file. The path to this configuration file can be stored in the environment variable `$BEDBASE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat bedhost/tutorial_files/bedbase_configuration.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inititiate a local elasticsearch cluster\n",
    "\n",
    "In addition to generate statistics and plots, [bedstat](https://github.com/databio/bedstat) inserts JSON formatted metadata into an [elasticsearch](https://www.elastic.co/elasticsearch/?ultron=[EL]-[B]-[AMER]-US+CA-Exact&blade=adwords-s&Device=c&thor=elasticsearch&gclid=Cj0KCQjwjcfzBRCHARIsAO-1_Oq5mSdze16kripxT5_I__EeH9F-xUCz_khEvzGL7q_mqP62CahJ9SIaAg2BEALw_wcB) database from which we'll search files and information about them. (This step may have to be performed outside the notebook since these commands ask for a sudo password. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If docker is not already installed, you can do so with the following commands\n",
    "#(make sure you have sudo permissions)\n",
    "\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-engine -y\n",
    "\n",
    "# Create a persistent volume to house elastic search data\n",
    "sudo docker volume create es-data\n",
    "\n",
    "# Run the docker container for elasticsearch\n",
    "sudo docker run -p 9200:9200 -p 9300:9300 -v es-data:/usr/share/elasticsearch/data -e \"xpack.ml.enabled=false\" \\\n",
    "  -e \"discovery.type=single-node\" elasticsearch:7.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run bedstat  on the demo PEP\n",
    "To run [bedstat](https://github.com/databio/bedstat) and the other required pipelines in this demo, we will rely on the pipeline submission engine [looper](http://looper.databio.org/en/latest/),which can be installed in the following manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user loopercli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to establish a modular connection between a project and a pipeline, we'll need to create a [pipeline interface](http://looper.databio.org/en/latest/linking-a-pipeline/) file, which tells looper how to run the pipeline. If `bedstat` is being run from an HPC environment where docker is not available, we recommend running the pipeline using the `--no-db-commit` flag (this will only calculate statistics and generate plots but will not insert this information into the local elasticsearch cluster. Once we have generated plots and statistics, we can insert them into our local elasticsearch cluster running `bedstat` with the `--just-db-commit` flag. If your data lives on a local environment, as it's the case in this tutorial, it's not necessary to set those flags and we can run bedstat in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looper run bedhost/tutorial_files/PEPs/bedstat_config.yaml --bedbase-config bedhost/tutorial_files/bedbase_configuration.yaml \\\n",
    "--no-db-commit --compute local --limit 10 -R > outputs/bedstat_output/bedstat_pipeline_logs/looper_logs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looper run bedhost/tutorial_files/PEPs/bedstat_config.yaml --bedbase-config bedhost/tutorial_files/bedbase_configuration.yaml \\\n",
    "--just-db-commit --compute local --limit 10 -R > outputs/bedstat_output/bedstat_pipeline_logs/looper_logs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for informative purposes, we can inspect how bedstat encapsulates the information for each bed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head outputs/bedstat_output/bedstat_pipeline_logs/looper_logs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous steps have been executed, our BED files should be available for query on our local elastic search cluster. Files can be queried using the `bedbuncher` pipeline described in the below section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEDBUNCHER: Create bedsets and their respective statistics \n",
    "\n",
    "### Create a new PEP describing the bedset name and specific JSON query  \n",
    "[bedbuncher](https://github.com/databio/bedbuncher) is a pipeline designed to create bedsets (sets of BED files retrieved from bedbase), with their respective statistics and additional outputs such as a `PEP` and an `iGD` database. In order to run `bedbuncher`, we will need to design an additional PEP describing the query as well as attributes such as the name assigned to the newly created bedset. This configuration file should point to the `JSON` file describing the query to find files of interest. The configuration file should have the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat bedhost/tutorial_files/PEPs/bedbuncher_query.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat bedhost/tutorial_files/PEPs/bedbuncher_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create outputs directory and install bedbuncher CML dependencies\n",
    "\n",
    "We need a folder where we can store `bedset` related outputs. Though not required, we'll also create a directory where we can store the `bedbuncher` pipeline logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir outputs/bedbuncher_output\n",
    "mkdir outputs/bedbuncher_output/bedbuncher_pipeline_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the feats of `bedbuncher` includes [iGD](https://github.com/databio/iGD) database creation from the files in the bedset. `iGD` can be installed by cloning the repository from github, executing the make file to create the binary, and pointing the binary location with the `$PATH` environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone git@github.com:databio/iGD\n",
    "cd iGD\n",
    "make > igd_make_log.txt\n",
    "cd ..\n",
    "\n",
    "#Add iGD bin to PATH (might have to do this before starting the tutorial) Something like \n",
    "export PATH=$BBTUTORIAL/iGD/bin/:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run bedbuncher using Looper \n",
    "\n",
    "Once we have cloned the `bedbuncher` repository, set our local elasticsearch cluster and created the `iGD` binary, we can run `bedbuncher` passing the location of the `bedbase` configuration file to the argument `--bedbase-config`. Note: if the path to the `bedbase` configration file has been stored in the `$BEDBASE` environment variable, it's not neccesary to pass the `--bedbase-config` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looper run  bedhost/tutorial_files/PEPs/bedbuncher_config.yaml  --bedbase-config bedhost/tutorial_files/bedbase_configuration.yaml \\\n",
    "--compute local -R > outputs/bedbuncher_output/bedbuncher_pipeline_logs/looper_logs.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEDHOST:  API to explore pipeline outputs\n",
    "\n",
    "The last part of the tutorial consists on running a local instance of [bedhost](https://github.com/databio/bedhost/tree/master) (a REST API for bedstat and bedbuncher produced outputs) in order to explore plots, statistics and download pipeline outputs. To run `bedhost`, we'll pip install the package from the previously cloned repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bedhost/. --user > bedhost_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start bedhost, we simply need to run the following commands passing the location of the `bedbase` config file to the `-c` flag.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedhost serve -c  $BBTUTORIAL/bedhost/tutorial_files/bedbase_configuration.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have stored the path to the bedbase config in the environment variable `$BEDBASE` (suggested), it's not neccesary to pass the `-c` flag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedhost serve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bedhost` API can be opened in the url [http://0.0.0.0:8000](http://0.0.0.0:8000). We can now explore the plots and statistics generated by the `bedstat` and `bedbuncher` pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "329.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
