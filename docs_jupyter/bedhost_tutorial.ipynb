{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BEDHOST Demo**\n",
    "\n",
    "The following demo has the purpose of demonstrating how to process, generate statistics and plots of BED files genrated by the R package Genomic Distributions using the REST API for the bedstat and bedbuncher pipelines. \n",
    "\n",
    "The general workflow for uploading bed files and their \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First part of the tutorial (insert BED files stats into elastic)\n",
    "\n",
    "\n",
    "### 1) Create a PEP describing the BED files to process\n",
    "\n",
    "In order to get started, we'll need a PEP [Portable Encapsulated project](https://pepkit.github.io/). A PEP consists of 1) an annotation sheet (.csv) that contains information about the samples on a project and 2) a project config.yaml file that points to the sample annotation sheet. THe config file also has other components, such as derived attributes, that in this case point to the BED files to be processed. The following is an example of a config file using the derived attributes output_file_path and yaml_file to point to the `.bed.gz` files and their respective metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata:\n",
      "  sample_table: demo_annotation_sheet.csv\n",
      "  output_dir: $HOME/Desktop/bedstat/bedhost_demo_files_justBED/bedstat_pipeline_results \n",
      "  pipeline_interfaces: ../../pipeline_interface.yaml\n",
      "\n",
      "constant_attributes: \n",
      "  output_file_path: \"source\"\n",
      "  yaml_file: \"source2\"\n",
      "  protocol: \"bedstat\"\n",
      "\n",
      "derived_attributes: [output_file_path, yaml_file]\n",
      "data_sources:\n",
      "  source: \"../{file_name}\" \n",
      "  source2: \"$HOME/Desktop/bedstat/bedhost_demo_files_justBED/bedstat_pipeline_results/submission/{sample_name}.yaml\""
     ]
    }
   ],
   "source": [
    "cat demo_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Download the Bedbase configration manager (bbconf)\n",
    "\n",
    "[bbconf](https://github.com/databio/bbconf) implements convenience methods for interacting with the database backend, which in this case is defined by an Elastic search local cluster. For carrying out this demo, we'll be using the dev version of `bbconf` that can be download as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone -b dev git@github.com:databio/bbconf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use bbconf, we'll need to create a minimal configuration.yaml file. The path to this configration file can be stores as the environmental variable `$BEDBASE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:\n",
      "  pipelines_output: $LABROOT/resources/regions/bedstat_output\n",
      "\n",
      "database:\n",
      "  host: localhost\n",
      "  bed_index: bed_index\n",
      "  bedset_index: bedset_index\n",
      "\n",
      "server:\n",
      "  host: 0.0.0.0\n",
      "  port: 8000\n"
     ]
    }
   ],
   "source": [
    "cat $BEDBASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Run the bedstat pipeline on the demo PEP\n",
    "\n",
    "[bedstat](https://github.com/databio/bedstat) is a pypiper pipeline that generates statistics and plots of BED files. For more detailed information about the pipeline and how to set a local elastic search cluster to insert and query files, click [here](https://github.com/databio/bedstat/blob/master/README.md) \n",
    "\n",
    "To run [bedstat](https://github.com/databio/bedstat) and the other required pipelines in this demo, we will rely on the pipeline submission engine [looper](http://looper.databio.org/en/latest/). For detailed instructions in how to link a project to a pipeline, click [here](http://looper.databio.org/en/latest/linking-a-pipeline/). If the pipeline is being run from an HPC environment where docker is not available, we recommend running the pipeline using the `--no-db-commit` flag (this will only calculate statistics and generate plots but will not insert this information into the local elasticsearch cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/Desktop/bedstat\n",
    "looper run bedhost_demo_files_justBED/bedhost_demo_refPEP/demo_config.yaml --no-db-commit --compute local "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have generated plots and statistics, we can insert them into our local elastic search cluster running the bedstat pipeline with the `--just-db-commit` flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/Desktop/bedstat\n",
    "looper run bedhost_demo_files_justBED/bedhost_demo_refPEP/demo_config.yaml --just-db-commit --compute local "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous steps have been executed, our BED files should be available for query on our local elastic search cluster. Files can be queried using the `bedbuncher` pipeline described in the below section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second part of the tutorial (use bedbuncher to create bedsets)\n",
    "\n",
    "### 1) Create a new PEP describing the bedset name and specific JSON query  \n",
    "[bedbuncher](https://github.com/databio/bedbuncher) is a pipeline designed to create bedsets (sets of BED files retrieved from bedbase). In order to create bedsets, we will need to create an additional PEP describing the query as well as attributes such as the name assigned to the newly created bedset. This configuration file should descibe the path to the `JSON` query file. THe configuration file should have the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_name,bedset_name,JSONquery_name,bbconfig_name,JSONquery_path,output_folder_path\n",
      "bedset1,test_bedset_igd,test_query,bbconfig,source1,source2\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/bedbuncher/project\n",
    "cat bedset_query.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata:\n",
      "  sample_table: bedset_query.csv\n",
      "  output_dir: . \n",
      "  pipeline_interfaces: ../pipeline_interface.yaml \n",
      "\n",
      "derived_attributes: [JSONquery_path]\n",
      "data_sources:\n",
      "  source1: ~/Desktop/bedbuncher/tests/{JSONquery_name}.json\n",
      " \n",
      "constant_attributes:\n",
      "  protocol: \"bedbuncher\""
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/bedbuncher/project\n",
    "cat cfg.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Run the bedbuncher pipeline with looper\n",
    "\n",
    "In order to create a bedset, we simply need to create a PEP as previously shown and run the bedbuncher pipeline using looper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/Desktop/bedbuncher\n",
    "looper run project/cfg.yaml --compute local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third part of the demo (run local instance of bedhost)\n",
    "\n",
    "The last part of the tutorial consists on running a local instance of [bedhost](https://github.com/databio/bedhost/tree/master) (a REST API for bedstat and bedbuncher produced outputs) in order to explore and download output files. To access the API, we'll need to download the dev branch of the github repository as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone -b dev git@github.com:databio/bedhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to run the following command, making sure to point to the previously described bedbase config.yaml file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedhost serve -c path/to/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have stored the path to the bedbase config in the environment variable `$BEDBASE` (suggested), it's not neccesary to specify the path to start bedhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedhost serve "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
